# -*- coding: utf-8 -*-
"""Books_recomendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OzyQdeyYbUh3dlDaDwNTa9Trwhz4ah5M

# Project Over view

<p align = "Justify">Perkembangan industri buku saat ini terus mengalami kemajuan, dengan banyaknya judul dan penulis yang menawarkan cerita menarik, informatif, dan menginspirasi. Penerbit besar maupun independen berlomba-lomba menyajikan karya terbaik mereka, baik dalam bentuk cetak maupun digital. Di era digital sekarang, platform pembelian dan pembacaan buku seperti Goodreads, Amazon, dan Google Books semakin memudahkan kita untuk mengakses ribuan bahkan jutaan judul buku.Namun, dengan begitu banyaknya pilihan buku yang tersedia, pembaca seringkali kebingungan dalam memilih buku yang sesuai dengan selera dan kebutuhannya. Hal ini juga menjadi tantangan tersendiri bagi penulis dan penerbit untuk mengetahui preferensi pembaca dan tren pasar.Oleh karena itu, sistem rekomendasi buku hadir sebagai solusi untuk membantu pembaca menemukan buku yang sesuai dengan minat mereka berdasarkan judul, Author, rating, dan preferensi pengguna lainnya. Sistem ini juga dapat membantu penerbit dan penulis memahami arah selera pasar dalam pengembangan buku selanjutnya.</p>

# Buisnees Understanding

### Problem
* Bagaimana cara melakukan pra-pemrosesan pada data Dataset yang akan digunakan agar dapat membuat model yang baik menggunakan teknik content based filtering dan dan collaborative filtering?
* Bagaimana memberikan rekomendasi Buku berdasarkan Data pada setiap judul Buku yang pelanggan input sehingga dapat memberikan preferensi yang sesuai Konsumen inginkan?

### Goals
* Melakukan pra-pemrosesan pada dataset agar nantinya dapat diproses pada model yang menggunaan teknik content based filltering dan collaborative filltering.
* Memberikan referensi judul buku untuk mempermudah pelanggan mencari buku yang sesuai dengan selera mereka dengan model yang sudah dibangun.

### Problem Statment
untuk mencapai Goals yang ada dapat melakukan bebrapa solusi yaitu :
* Untuk tujuan pertama, melakukan pra-pemrosesan data dengan bebrapa teknik yaitu:
  * Memeriksa masalah data yang ada dalam dataset.
  * Melakukan visualisasi data untuk mempelajari data.
  * Membersihkan judul buku yang duplikat dalam dataset
* Untuk tujuan kedua yaitu membuat rekomendasi judul buku kepada pengguna dengan menggunakan dua metode yaitu Content based filltering dan collaborative filltering.
  * Content based filltering.
    <br>adalah metode yang memilih item berdasarkan korelasi antara konten item dan preferensi pengguna <a href = "https://users.ics.forth.gr/~potamias/mlnia/paper_6.pdf">[2]</a>, Content-based filtering
    mempelajari profil minat pengguna baru berdasarkan data dari objek yang telah
    dinilai pengguna. Algoritma ini bekerja dengan menyarankan item serupa yang pernah disukai di masa lalu atau sedang dilihat di masa kini kepada pengguna. Metode ini memiliki kelebihan dan kekurangan
    diantarinya adalah :
    * Kelebihan
      <br>Metode ini tidak bergantung pada pengguna lain karena menggunakan data milik sendiri.
    * Kekurangan
      <br>Tidak cocok untuk new user karena metode ini sangat memerlukan data riwayat dari pengguna.
  * Collaborative filltering
    <br>adalah metode yang bekerja dengan dengan mencari sekelompok besar orang dan menemukan sekelompok kecil pengguna dengan selera yang mirip dengan pengguna tertentu. Ia melihat item yang mereka sukai dan
    menggabungkannya untuk membuat daftar saran yang diberi peringkat. Metode ini juga memiliki kelebihan dan kekurangan yaitu :
    * Kelebihan
      <br>Metode ini tidak bergantung pada informasi item secara eksplisit karena mengandalkan pola interaksi antar pengguna.
    * Kekurangan
      <br>Tidak cocok untuk pengguna baru karena metode ini sangat memerlukan riwayat interaksi untuk menghasilkan rekomendasi.

## Import Libary yang dibutuh
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer

"""## Data Understanding

Dalam Project ini menggunakan dataset yang sudah tersedia dalam situs Kaggle, dimana data ini memiliki 3 buah data inti yaitu data buku, rating, user pada data ini terdapat fitur yang bisa digunakan untuk membuat sebuah sistem rekomendasi yang bisa memberikan referensi buku yang sesuai dengan pendekatan dari pengguna. <br>
Referensi [Dataset](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset/data) <br>
"""

Books = pd.read_csv('/content/drive/MyDrive/Books.csv')
Ratings = pd.read_csv('/content/drive/MyDrive/Ratings.csv')
Users = pd.read_csv('/content/drive/MyDrive/Users.csv')

print("Jumlah Data Buku : ", len(Books))
print("Jumlah Data Rating : ", len(Ratings))
print("Jumlah Data User : ", len(Users))

"""Pada Data ini terdapat 3 file csv <br>


*   Books.csv <br>
Berisikan Data dari Buku yang ada mulai dari Judul, Author, Publiser, tahun rilis dan yang lainnya yang berkaitan dengan Buku
*   Ratings.csv <br>
Berisikan Data Penilaian pada Buku dari User yang membacanya
*  User.csv <br>
Berisikan data dari pembaca / User mulai dari umur sampai tempat tinggal mereka


"""

Books.info()

"""### Books CSV
Pada data Books.csv terdapat 8 kolom data yang berisikan 271360 baris data.<br>
- ISBN Merupakan kode unik identifikasi buku (International Standard Book Number).
- Book-Title Data Judul Buku yang ada
- Book-Author Data Penulis Buku
- Year-Of-Publication Data Tahun Buku itu diterbitkan
- Publisher Data Para Publisher Buku
- Image-URL-S Data URL gambar kecil dari sampul buku.
- Iamage-URL-M Data URL gambar sedang dari sampul buku.
- Image-URL-L Data URL gambar besar dari sampul buku.
"""

Ratings.info()

"""### Rating CSV
Pada data Rating.csv terdapat 3 kolom data yang berisikan 1149780 baris data <br>
- User-Id adalah Data ID dari User
- ISBN adalah kode unik dari buku (International Standar Book Number)
- Book Rating Data Rating dari user untuk Buku yang dibaca

"""

Users.info()

"""### User CSV
Pada data User.csv terdapat 3 kolom data yang berisikan 278858  baris data <br>
- User-Id adalah Data ID dari User
- Location adalah yang berisikan location dari User
- Age adalah data yang berisikan info umur dari User

# EDA (Explonary Data Analysis)
"""

print(Books.shape)
print(Users.shape)
print(Ratings.shape)

"""Dilihat Data Books memiliki 8 kolom dengan jumlah baris per kolom adalah 271360 <br>
Untuk Data User memilki 3 kolom dengan jumlah baris per kolom adalah 278858 <br>
Dan untuk Data Ratings memiliki 3 kolom dengan jumlah baris per kolom adalah 1149780
"""

# Memeriksa Nilai Missing Value
print("Nilai Missing Value pada Data Books:")
print(Books.isnull().sum(), "\n")

print("Nilai Missing Value pada Data Users:")
print(Users.isnull().sum(), "\n")

print("Nilai Missing Value pada Data Ratings:")
print(Ratings.isnull().sum())

"""Dilihat Pada colom Age pada data User terdapat nilai Missing Value yang sangat besar, namun akan sangat beresiko untuk menghapus 110762 data tersebut karena akan sangat berpengaruh pada model nantinya

"""

# Memeriksa Nilai Duplikat
print("Nilai Duplikat pada Data Books:")
print(Books.duplicated().sum(), "\n")

print("Nilai Duplikat pada Data Users:")
print(Users.duplicated().sum(), "\n")

print("Nilai Duplikat pada Data Ratings:")
print(Ratings.duplicated().sum())

"""Disemua dataset bersih dengan tidak ada data yang duplikat

## Visual Data

Selanjutnya yaitu melakukan visualisasi dengan tujuan yaitu:
* Melihat Author Terbanyak dan Top Publisher
* Melihat Trend Tahun Distribusi Buku
* Melihat Jumlah Rating Buku

### Mencari Top Author dan Top Publisher
"""

total_author = Books['Book-Author'].value_counts().reset_index(name='Count').sort_values('Count', ascending=False).head(15)

total_publisher = Books['Publisher'].value_counts().reset_index(name='Count').sort_values('Count', ascending=False).head(15)

fig, (ax1,ax2) = plt.subplots(ncols=2, figsize=(12,6))

ax1 = sns.barplot(data=total_author, x='Book-Author', y='Count', ax=ax1)
ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, fontsize=6)
ax1.set_title('Author Terbanyak', size=30)

ax2 = sns.barplot(data=total_publisher, x='Publisher', y='Count', ax=ax2)
ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45, fontsize=6)
ax2.set_title('Top Publishers', size=30)

plt.tight_layout()

"""Disini Dilihat Bahwa Untuk Author Terbanyak yaitu ada Agatha Christie sebanyak lebih dari 600 buku yang ada dan kemudian di bagian publisher yaitu ada Harlequin yang menjadi top publisher dengan lebih dari 7000 buku

### Melihat Tren Distribusi Buku
"""

Books['Year-Of-Publication'] = pd.to_numeric(Books['Year-Of-Publication'], errors='coerce')

plt.figure(figsize=(10, 6))
sns.histplot(Books['Year-Of-Publication'].dropna(), bins=30, kde=True, color='coral')
plt.title("Distribusi Tahun Terbit Buku")
plt.xlabel("Year of Publication")
plt.ylabel("Count")
plt.show()

"""Pada Chart Di atas, dilihat ada sedikit kejanggalan yaitu ada buku yang diterbitkan pada tahun 0, mungkin ada kesalahan pada colom Year-Of-Publication. namun juga bisa dilihat bahwa sebagian besar buku di distribusi pada tahun 2000"""

Books['Year-Of-Publication'].unique()

"""Dilihat disini terdapat data yang bernilai 0 dan ada juga yang bernilai Nan"""

plt.figure(figsize=(10, 6))
sns.countplot(x='Book-Rating', data=Ratings, palette='viridis')
plt.title("Book Ratings")
plt.xlabel("Book Rating")
plt.ylabel("Count")
plt.show()

Ratings['Book-Rating'].value_counts()

"""Dilihat Dari Data ini Ada Banyak Buku yang mendapatkan rating 0, dan yang paling dikit adalah buku yang mendpatkan rating 1

# Data Preparation

Pada Tahapan ini ada beberapa yang perlu dilakukan untuk selanjutnya membuat Model Yaitu:
* Memperbaiki type data pada colom Year-Of-Publication dan Age
* Memperbaiki data yang memiliki missing value
* Menghapus data nan pada Year-of-publication
* Menggabung Dataset Books dan Ratings

### Memperbaiki Type Data
"""

Books['Year-Of-Publication'] = Books['Year-Of-Publication'].astype('Int64')
Users['Age'] = Users['Age'].astype('Int64')

Books.info()

Users.info()

"""### Memperbaiki Missing Value"""

Books = Books.dropna(subset=['Book-Author', 'Publisher', 'Image-URL-L'])

Books.isnull().sum()

Books.info()

"""Untuk Bagian Colom Age, akan menggunakan metode mengisi nilai Missing Value dengan median dari nilai colom Age"""

Users['Age'].describe()

Users['Age'] = Users['Age'].fillna(Users['Age'].median())

Users.isnull().sum()

"""### Menghapus data nan pada Year-of-publication

"""

Books = Books[Books['Year-Of-Publication'].notna()]
Books = Books[(Books['Year-Of-Publication'] >= 1900) & (Books['Year-Of-Publication'] <= 2025)]

Books['Year-Of-Publication'] = pd.to_numeric(Books['Year-Of-Publication'], errors='coerce')

plt.figure(figsize=(10, 6))
sns.histplot(Books['Year-Of-Publication'].dropna(), bins=30, kde=True, color='coral')
plt.title("Distribusi Tahun Terbit Buku")
plt.xlabel("Year of Publication")
plt.ylabel("Count")
plt.show()

Books['Year-Of-Publication'].unique()

"""### Menggabung Dataset Books dan Ratings

Untuk Membuat system rekomendasi, kita akan menggunakan dua dataset Ratings dan Books untuk mencari rekomendasi buku dengan referensi ratings, dan juga dengan menggabungkan kedua data buku dan rating untuk mendapatkan top buku populer yang ada
"""

rating_buku = Ratings.merge(Books,on='ISBN')
rating_buku.head()

jumlah_rating = rating_buku.groupby('Book-Title').count()['Book-Rating'].reset_index()
jumlah_rating.rename(columns={'Book-Rating':'num_ratings'},inplace=True)
jumlah_rating.head()

"""kode ini membuat kita mendapatkan berapakali sebuah buku itu mendapatkan rating dari User

"""

rata_rating = rating_buku.groupby('Book-Title')['Book-Rating'].mean().reset_index()

rata_rating.rename(columns={'Book-Rating': 'avg_rating'}, inplace=True)

rata_rating.head()

"""Dalam Kode ini kita mencari nilai rata-rata rating dari sebuah buku"""

popular_buku = jumlah_rating.merge(rata_rating, on='Book-Title')

popular_buku.head()

"""Dalam Kode ini kita menambahkan jumlah rating dan rata-rata rating ke dalam dataframe Book-Title, untuk diolah agar mendapatkan list buku populer dalam dataset

"""

popular_buku = popular_buku[popular_buku['num_ratings'] >= 300]

popular_buku = popular_buku.sort_values('avg_rating', ascending=False).head(50)

"""Untuk mencari buku yang populer harus memahami bahwa buku yang banyak diberi rating berarti buku itu memiliki potensi untuk menjadi buku yang populer. pada kode ini kita mengatur untuk menampilkan buku yang dirating lebih dari 300 kali dan menampilkan 50 buku yang memiliki rata-rata rating paling tinggi"""

popular_buku = popular_buku.merge(Books,on='Book-Title').drop_duplicates('Book-Title')[['Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating']]

"""Dalam dataframe populer buku menambahkan colom 'Book-Title','Book-Author','Image-URL-M','num_ratings','avg_rating' untuk memudahkan dibaca"""

popular_buku

"""# Modeling and Result

Dalam Proyek ini memakai dua algoritma yaitu :


*   Collaborative Filtering
*   content based filltering

### Collaboraive Filtering

Collaborative filltering adalah sistem rekomendasi yang berdasarkan kemiripan dari rating yang diberikan oleh user kepada buku<br> pada metode ini menggunakan base model yaitu matrix factorization
"""

user_rating_counts = rating_buku.groupby('User-ID').count()['Book-Rating'] > 200

good_reader = user_rating_counts[user_rating_counts].index

filtered_rating = rating_buku[rating_buku['User-ID'].isin(good_reader)]

y = filtered_rating.groupby('Book-Title').count()['Book-Rating']>=50
famous_books = y[y].index

final_ratings = filtered_rating[filtered_rating['Book-Title'].isin(famous_books)]

pt = final_ratings.pivot_table(index='Book-Title',columns='User-ID',values='Book-Rating')

pt.fillna(0,inplace=True)

pt.head()

similarity_scores = cosine_similarity(pt)

similarity_scores.shape

def recommend(book_name):
    """
    Memasukan Judul Buku, dan function ini akan memberikan top 5 buku yang mirip
    sesuai dengan consep collaborative filltering
    """

    index = np.where(pt.index == book_name)[0][0]

    similar_items = sorted(list(enumerate(similarity_scores[index])),
                           key=lambda x: x[1], reverse=True)[1:6]

    recommendations = []

    for i in similar_items:
        book_info = []
        temp_df = Books[Books['Book-Title'] == pt.index[i[0]]]

        book_info.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Title'].values))
        book_info.extend(list(temp_df.drop_duplicates('Book-Title')['Book-Author'].values))
        book_info.extend(list(temp_df.drop_duplicates('Book-Title')['Image-URL-M'].values))


        recommendations.append(book_info)

    return recommendations

recommend('Harry Potter and the Prisoner of Azkaban (Book 3)')

"""### Content Based Filltering

Pada Metode Content Based Filltering disini menggunakan kemiripan yaitu author yang mirip atau memiliki gaya penulisan yang sama, jadi jika user menyukai karya author A maka sistem akan memberikan rekomendasi author yang memiliki penulisan yang mirip
"""

author_df = Books[['Book-Author']].drop_duplicates()
author_df = author_df[author_df['Book-Author'].notna()].reset_index(drop=True)

author_df.head()

# Vectorizer + TF-IDF
vectorizer = TfidfVectorizer()
author_matrix = vectorizer.fit_transform(author_df['Book-Author'])

# Mapping nama penulis ke index
author_to_index = pd.Series(author_df.index, index=author_df['Book-Author'].str.lower()).drop_duplicates()

from sklearn.metrics.pairwise import cosine_similarity

def get_similar_authors_efficient(author_name, top_n=5):
    author_name = author_name.lower()

    if author_name not in author_to_index:
        return "Penulis tidak ditemukan."

    idx = author_to_index[author_name]
    author_vec = author_matrix[idx]  # ini sparse, hemat RAM

    # Hitung kemiripan hanya dari 1 ke semua
    similarities = cosine_similarity(author_vec, author_matrix)[0]

    # Urutkan dan ambil top N
    similar_indices = similarities.argsort()[::-1][1:top_n+1]
    similar_authors = author_df.iloc[similar_indices]['Book-Author'].values.tolist()

    return similar_authors

get_similar_authors_efficient("Richard Bruce Wright")

"""# EVALUASI

Pada Proyek ini membuat dua buah metode yaitu:
* pertama menggunakan Collborative filltering, untuk mencari rekomendasi buku berdasarkan rating yang diberi User
* Kedua adalah menggunakan Conten Based Filltering

Dua Metode itu menggunakan cara kerja yang berbeda atau matriks yang beda. <br>
* Untuk yang pertama ada menggunakan Pivot table untuk melihat user ID berapa yang memberi rating paa sebuah Buku
* Dan pada metode kedua menggunakan TF-ID yaitu metode yang berkerja dengan cara mengubah teks menjadi angka berdasarkan:
  * TF: Seberapa sering suatu kata muncul dalam satu dokumen
  * IDF: Seberapa jarang kata itu muncul di seluruh dokumen
<br>
Dengan itu bisa mencari data kemiripian untuk Metode kedua.

## Apakah Sudah Menjawab Problem Statment :

* Bagaimana cara melakukan pra-pemrosesan pada data Dataset yang akan digunakan agar dapat membuat model yang baik menggunakan teknik content based filtering dan dan collaborative filtering?<br>
Untuk Menjawab Problem Statment ini sudah dijawab pada procesing Data, dimana data dibersihkan mulai dari type data yang tidak cocok, data yang memiliki banyak sekali missing value, data yang terdapat data Nan dan 0 contohnya pada data colom "Year-Of-Publication" yang mengakibatkan grafik awal sebelum procesing data terlihat buruk dan sudah lebih baik pada selesai processing data, dan ditahap procesing data juga sudah menggabungkan dataset books dan ratings untuk nantinya dipakai dalam model
* Bagaimana memberikan rekomendasi Buku berdasarkan Data pada setiap judul Buku yang pelanggan input sehingga dapat memberikan preferensi yang sesuai Konsumen inginkan?
Untuk Pertanyaan ini sudah dijawab dari hasil model yang dibuat, untuk metode Collaborative Filltering sudah mendapatkan rekomendasi buku berdasarkan rating. kemudian pada metode kedua adalah mendapatkan rekomendasi author berdasarkan author kesukaan untuk mencari author yang memiliki cara dan taste yang sama

## Apakah berhasil mencapai setiap goals yang diharapkan? :
* Melakukan pra-pemrosesan pada dataset agar nantinya dapat diproses pada model yang menggunaan teknik content based filltering dan collaborative filltering.<br>
Goals ini sudah terjawab pada tahap Processing data, dimana sudah berhasil untuk memperbaiki type data, missing value, kesalahan value dan menggabungkan dataset untuk membuat model.
* Memberikan referensi judul buku untuk mempermudah pelanggan mencari buku yang sesuai dengan selera mereka dengan model yang sudah dibangun. <br>
Goals ini berhasil dengan berjalannya metode collaborative filltering dan memberikan rekomendasi buku

## Apakah setiap solusi statement yang kamu rencanakan berdampak? :
* Untuk Problrem Statment Pertama Melakukan pra-pemrosesan data:
Tahap ini sudah Berdampak pada tahap praprocesing data dengan tidak adanya type data yang salah, missing value dan feature baru yang berisikan data yang sudah siap untuk permodelan.<br>

* Untuk Problem Statment Kedua yaitu melakukan dua metode Collaborative Filltering dan Content Based Flltering: Tahap ini juga sudah berhasil dengan output rekomendasi buku dan author yang diberikan dari kedua metode tersebut
"""